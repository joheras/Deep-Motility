# -*- coding: utf-8 -*-
"""Copia de Mask-RCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jjz9EDiA0SCoGuZx-aHAy2b6x4RNfiAd
"""

from fastai.basics import *
from fastai.vision import models
from fastai.vision.all import *
# from fastai2.metrics import *
from fastai.data.all import *
from fastai.callback import *

# SemTorch
from semtorch import get_segmentation_learner

# MaskRCNN Data Utils
from semtorch.models.archs.mask_rcnn import MaskRCNNBlock, IntToFloatTensorMaskRCNN, TfmdDLV2, MaskRCNNDict

# MaskRCNN metrics
from semtorch.utils.metrics import DiceMaskRCNN, JaccardCoeffMaskRCNN


from pathlib import Path
import random

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import torch
torch.cuda.set_device(2)

"""Function por stablishing the seed for reproducibility"""

number_of_the_seed = 2020

random.seed(number_of_the_seed)
set_seed(number_of_the_seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

path = Path("dataset/")
path_images = path/"Images"
path_labels = path/"Labels"

test_name = "test"

"""Obtaining the label associated with an image, in the case of segmentation it is a mask"""

get_y_fn = lambda x: Path(str(x).replace("Images","Labels").replace(".jpg",".png"))

"""Aux function for splitting between training and testing"""

def ParentSplitter(x):
    return Path(x).parent.name==test_name

"""Loading the codes of the different classes. All the datasets have the same codes."""

codes = np.loadtxt(path/'codes.txt', dtype=str)

name2id = {v:k for k,v in enumerate(codes)}
print(name2id)
void_code = name2id['Bacteria']

def tumour(input, target):
    res=0
    for i in range(len(input)):
        inputAux=input[i]["masks"]
        targetAux=target[i]["masks"]
        targetAux = targetAux.squeeze(1)

        if inputAux.shape[0]>0:
            inputAux=inputAux[0]
        else:
            inputAux=torch.zeros(targetAux.shape).to(targetAux.device)

        #print(input.shape)
        #print(target.shape)
        mask = targetAux != void_code
        res+=(inputAux[mask]==targetAux[mask]).float().mean()
    return res/len(input)

"""Early Stopping parameters"""

monitor_training="valid_loss"
comp_training=np.less

monitor_evaluating="dice"
comp_evaluating=np.greater

patience=2

from albumentations import (
    Compose,
    OneOf,
    ElasticTransform,
    GridDistortion, 
    OpticalDistortion,
    Flip,
    VerticalFlip,
    Rotate,
    Transpose,
    CLAHE,
    ShiftScaleRotate
)

class SegmentationAlbumentationsTransform(ItemTransform):
    split_idx = 0
    def __init__(self, aug): 
        self.aug = aug
    def encodes(self, x):
        img,target = x
#         print(img.shape)
#         print(target["masks"])
#         print("AUG TRANSFORM ",np.array(target["masks"])[0].shape)
        
#         img1 = img
#         img1.show(figsize=(5, 5))
#         mask1 = PILMask.create(np.array(target["masks"])[0])
#         mask1.show(figsize=(5, 5), alpha=1)
        
        # Transform
#         print('Despues')
        #print(np.array(img).shape)
        #print(np.array(target["masks"]))
        aug = self.aug(image=np.array(img), mask=np.array(target["masks"])[0])
        
        target["masks"]=aug["mask"]
        pos = np.where(target["masks"])
        xmin = np.min(pos[1])
        xmax = np.max(pos[1])
        ymin = np.min(pos[0])
        ymax = np.max(pos[0])
        
        target["masks"]=np.expand_dims(target["masks"], axis=0)
        target["masks"]=TensorMask(target["masks"])
        #print("AUG ",target["masks"].shape)
        target["boxes"]=TensorBBox.create([xmin, ymin, xmax, ymax])
        
#         img2 = PILImage.create(aug["image"])
#         img2.show(figsize=(5, 5))
#         mask2 = PILMask.create(np.array(target["masks"])[0])
#         mask2.show(figsize=(5, 5), alpha=1)
        
        return PILImage.create(aug["image"]), target
    
transformPipeline=Compose([
                        Flip(p=0.5),
                        VerticalFlip(p=0.5),
                        Transpose(p=0.5),
                        Rotate(p=0.40,limit=10)
                    ],p=1)

transformPipeline=SegmentationAlbumentationsTransform(transformPipeline)

"""Definition of the splitter for saying the learner what weights of the network to freeze"""

def maskrcnn_splitter(model):
    return [params(model.backbone), params(model.rpn), params(model.roi_heads)]

"""Importing all the functions needed for Mask-RCNN

The getters for DataBlock. Returning same image as input and get dict of image as target
"""

def get_bbox(o):
    label_path = get_y_fn(o)
    mask=PILMask.create(label_path)
    pos = np.where(mask)
    xmin = np.min(pos[1])
    xmax = np.max(pos[1])
    ymin = np.min(pos[0])
    ymax = np.max(pos[0])
    
    return TensorBBox.create([xmin, ymin, xmax, ymax])
    
def get_bbox_label(o):
    
    return TensorCategory([1])

def get_mask(o):
    label_path = get_y_fn(o)
    mask=PILMask.create(label_path)
    mask = np.array(mask)

    # Change 255 for 1
    mask[mask==255]=1

    # Back to PILMask
    mask = PILMask.create(mask)
    mask=image2tensor(mask)
    return TensorMask(mask)

def get_dict(o):
    return {"boxes": get_bbox(o), "labels": get_bbox_label(o),"masks": get_mask(o)}

getters = [lambda o: o, get_dict]

"""# Mask-RCNN

## Manual Annotations
"""

manual_name="train"

path_manual_img = path_images/manual_name
path_manual_lbl = path_labels/manual_name

fnames_manual = get_image_files(path_manual_img)
lbl_names_manual = get_image_files(path_manual_lbl)

# open and show image
img_f = fnames_manual[10]
print(img_f)
img = PILImage.create(img_f)
img.show(figsize=(5, 5))

print(get_y_fn(img_f))

mask = PILMask.create(get_y_fn(img_f))
mask.show(figsize=(5, 5), alpha=1)

print(torch.max(image2tensor(mask)))

mask = PILMask.create(get_y_fn(img_f))
mask=image2tensor(mask)
example = {"boxes": 1, "labels": 1,"masks": mask}
s=MaskRCNNDict(example)
s.show()

size = 1002
bs = 2

"""### Data Augmentation"""

manual = DataBlock(
    blocks=(ImageBlock, MaskRCNNBlock),
    get_items=partial(get_image_files,folders=['train','test']),
    getters=getters,
    splitter=FuncSplitter(ParentSplitter),
    item_tfms=[transformPipeline,IntToFloatTensorMaskRCNN],
    dl_type=TfmdDLV2,
    n_inp=1
)
manual.summary(path_images)
dls = manual.dataloaders(path_images,bs=bs)

"""WD=1e-3"""

learn = get_segmentation_learner(dls=dls, number_classes=2, segmentation_type="Semantic Segmentation",
                                 architecture_name="maskrcnn", backbone_name="resnet50", 
                                 image_size=1002, metrics=[tumour, DiceMaskRCNN(), JaccardCoeffMaskRCNN()], wd=1e-3,
                                 splitter=maskrcnn_splitter)
# Just freezing backbone
learn.freeze_to(-2)

learn.lr_find() # find learning rate
learn.recorder # plot learning rate graph

fname="maskrcnn"

callbacksFitBeforeUnfreeze = [
    ShowGraphCallback(),
    EarlyStoppingCallback(monitor=monitor_training,comp=comp_training, patience=patience),
    SaveModelCallback(monitor=monitor_training,comp=comp_training,every_epoch=False,fname=fname)  
]
learn.fit_one_cycle(10, slice(1e-4,1e-3),cbs=callbacksFitBeforeUnfreeze)

learn.load("maskrcnn")
learn.validate()

learn.unfreeze()
learn.lr_find() # find learning rate
learn.recorder # plot learning rate graph

fname="maskrcnn"

callbacksFitAfterUnfreeze = [
    ShowGraphCallback(),
    EarlyStoppingCallback(monitor=monitor_training,comp=comp_training, patience=patience),
    SaveModelCallback(monitor=monitor_training,comp=comp_training,every_epoch=False,fname=fname)  
]
learn.fit_one_cycle(10, slice(3e-7,8e-7),cbs=callbacksFitAfterUnfreeze)

"""WD=1e-2"""

learn = get_segmentation_learner(dls=dls, number_classes=2, segmentation_type="Semantic Segmentation",
                                 architecture_name="maskrcnn", backbone_name="resnet50", 
                                 image_size=1002, metrics=[tumour, DiceMaskRCNN(), JaccardCoeffMaskRCNN()], wd=1e-2,
                                 splitter=maskrcnn_splitter)
# Just freezing backbone
learn.freeze_to(-2)
